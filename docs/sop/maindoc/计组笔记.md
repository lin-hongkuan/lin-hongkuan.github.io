---
title: 计算机组成原理
date: 2026-02-14 12:00:00
description: 计算机组成原理
tag:
  - 计算机组成原理
  - 硬件

top: 0
sticky: 0
---

# 计算机组成原理 期末复习整合笔记

---

## 【一】概论


### 1. 计算机系统的层次结构

#### 1.1 计算机系统的组成

计算机系统 = **硬件 + 软件**

* **硬件（Hardware）**

  * 运算器（ALU）
  * 控制器（CU）
  * 存储器（Memory）
  * 输入设备 / 输出设备（I/O）

* **软件（Software）**

  * 系统软件：操作系统、编译器、汇编器
  * 应用软件：用户程序

👉 **计组研究对象：硬件 + 硬件与软件的接口**

---

#### 1.2 计算机系统的多级层次结构（自下而上）

1. **数字逻辑级**（门电路）
2. **微结构级**（寄存器、微指令）
3. **机器语言级**（指令系统 ISA）
4. **操作系统级**（虚拟机）
5. **汇编语言级**
6. **高级语言级**

📌 重要思想：

* **每一层对上提供抽象，对下隐藏细节**
* 软件是“虚拟机”的实现

---

### 2. 冯·诺依曼结构

#### 2.1 冯·诺依曼计算机的五大部件

1. 运算器
2. 控制器
3. 存储器
4. 输入设备
5. 输出设备

#### 2.2 核心特点（必考）

* **存储程序**：

  * 程序和数据统一存放在存储器中
* **顺序执行**：

  * 指令通常按地址递增顺序执行
* **以运算器为中心**（现代计算机已弱化）

📌 缺点：

* **冯·诺依曼瓶颈**：

  * CPU 与存储器之间带宽受限

---

### 3. 程序的执行过程（宏观）

#### 3.1 程序翻译与执行流程

```text
高级语言程序
   ↓ 编译
汇编语言程序
   ↓ 汇编
机器语言程序
   ↓ 装入
内存
   ↓
CPU 执行
```

#### 3.2 指令执行的基本过程（指令周期）

1. **取指（Fetch）**
2. **译码（Decode）**
3. **执行（Execute）**
4. **访存（Memory）**（可选）
5. **写回（Write Back）**（可选）

📌 一条指令 ≠ 一个时钟周期

---

### 4. 计算机性能指标（重点）

#### 4.1 基本概念

* **响应时间（执行时间）**

  * 程序从开始到结束所用时间

* **吞吐率**

  * 单位时间内完成的任务数

📌 用户更关心：**响应时间**

---

#### 4.2 CPU 时间模型（核心公式）

```text
CPU 时间 = 指令数 × CPI × 时钟周期
```

或：

```text
CPU 时间 = 指令数 × CPI / 时钟频率
```

**MIPS（百万条指令每秒）**：$MIPS = \frac{f}{CPI \times 10^6}$ 或 $MIPS = \frac{IC}{T_{exec} \times 10^6}$

其中：

* 指令数（IC）：与程序和编译器有关
* CPI（Cycles Per Instruction）：与体系结构有关
* 时钟周期 / 频率：与硬件实现有关

📌 **性能优化三方向**：

* 减少指令数
* 降低 CPI
* 提高时钟频率

---

#### 4.3 性能对比原则（考试易错）

* **性能 ∝ 1 / 执行时间**
* A 比 B 快 n 倍：

```text
Performance_A / Performance_B = Time_B / Time_A = n
```

---

#### 4.4 Amdahl 定律（非常重要）

```text
加速比 S = 1 / [ (1 - f) + f / k ]
```

* f：可改进部分所占比例
* k：该部分的加速倍数

📌 结论：

* **系统性能受最慢、占比最大的部分限制**

---

### 5. 计算机的分类

#### 5.1 按用途

* 专用计算机
* 通用计算机

#### 5.2 按规模与性能

* 巨型机
* 大型机
* 小型机
* 微型机（PC）
* 嵌入式系统

---

### 6. 本章常考 & 易混点总结

* 冯·诺依曼结构的**核心特征**
* **CPU 时间公式**的三要素
* **CPI ≠ 1**（尤其在流水线中）
* 性能提升要看**整体加速比（Amdahl）**
* 层次结构的“抽象”思想

---

### 7. 一句话记忆版（考前速背）

* 计组：**软硬件接口 + 硬件结构**
* 冯·诺依曼：**存储程序、顺序执行**
* 性能：**时间越短，性能越好**
* CPU 时间：**IC × CPI × T**
* 优化极限：**Amdahl 定律**

---

## 【二】数据的表示和运算

本章涵盖数制与编码、定点与浮点数表示、C 语言类型与转换、字节序与对齐、以及定点数运算（移位、溢出、标志位）等内容。

### 数制和编码

进位计数制：二进制、八进制、十六进制及其相互转换。编码方式与下面「数据的表示与类型转换」中的定点数编码（原码、反码、补码、移码）紧密相关。

### 1. 数据的表示与类型转换

#### 1.1 整数表示

**定点数编码：**

- **原码**：最高位为符号位（0 正 1 负），其余为数值。0 有 +0 和 -0 两种表示；直观易懂，但与真值加减运算需判断符号。
- **反码**：正数同原码；负数符号位不变，数值位按位取反；多用作求补码的中间步骤。
- **补码**：正数同原码；负数 = 反码 + 1。0 只有一种表示，加减法统一为补码运算。核心：$[A+B]_补=[A]_补+[B]_补$，$[A-B]_补=[A]_补+[-B]_补$，利用模运算 $-x \equiv 2^n - x \pmod{2^n}$。
- **移码**：补码符号位取反，主要用于浮点数阶码，便于比较大小。

**表示范围（n 位整数）：**

- 原码/反码：$-(2^{n-1}-1) \sim +(2^{n-1}-1)$
- 补码：$-2^{n-1} \sim +(2^{n-1}-1)$（多表示一个最小负数 -128 等）

#### 1.2 浮点数表示（IEEE 754）**【重点】**

- 格式：$(-1)^S \times M \times 2^E$。单精度：S 1 位、E 8 位（Bias=127）、M 23 位；双精度：E 11 位（Bias=1023）、M 52 位。
- 规格化数：尾数隐含最高位 1，即 $1.M$。特殊值：E 全 0 且 M 非 0 为非规格化数；E 全 1、M 为 0 为无穷，M 非 0 为 NaN。
- 单精度范围约 $2^{-126} \sim (2-2^{-23})\times 2^{127}$；有效位约 7 位十进制；双精度约 16 位十进制。

#### 1.3 C 语言数据类型大小（参考）

- 常用：`int` 32 位/4 字节，`short` 16 位，`char` 8 位，`float` 32 位（有效约 24 位），`double` 64 位（有效约 53 位）。指针在 32/64 位系统分别为 4/8 字节。

#### 1.4 C 语言类型转换**【易错】**

- 有符号与无符号：**位模式不变**，仅解释方式不同；负数转无符号等价于 $2^n + \text{原值}$。
- 符号扩展（有符号）、零扩展（无符号）、截断（保留低 k 位，相当于对 $2^k$ 取模）。
- `int`→`float` 可能丢失精度（float 有效约 24 位）；`int`→`double` 通常精确；`float`→`int` 截断小数、向零舍入。

#### 1.5 数据存储与字节序**【重点】**

- **大端**：高位字节在低地址；**小端**：低位字节在低地址（x86 常用）。网络字节序为大端。可用 `char*` 指向多字节整数，看首字节判断大小端。

#### 1.6 边界对齐

- 基本类型地址为其大小的整数倍；结构体按成员对齐，总大小为最大成员对齐数的整数倍，中间可能有填充字节。对齐有利于访问效率与硬件要求。

### 2. 定点数运算

#### 2.1 移位运算

- **逻辑移位**（无符号）：空位补 0。
- **算术移位**（有符号补码）：左移低位补 0；右移**高位补符号位**，相当于除 2 向零取整。注意与逻辑右移区别（负数的逻辑右移会变成大正数）。

#### 2.2 溢出判断**【重点】**

- 单符号位法：正+正得负为上溢，负+负得正为下溢；正+负不溢出。
- 双符号位法（变形补码）：00 正、11 负为正常；01 上溢、10 下溢，$V=S_0 \oplus S_1$。

#### 2.3 标志位（PSW）**【重要】**

- **CF**：无符号运算进位/借位。
- **OF**：有符号溢出，$OF = C_n \oplus C_{n-1}$（最高位进位与次高位进位异或）。
- **ZF**：结果为 0；**SF**：结果符号位。

---

## 【三】指令系统

### 指令集体系结构
指令集体系结构（Instruction Set Architecture，ISA）是计算机体系结构的一个重要组成部分，它定义了计算机能够执行的指令类型、指令格式、寻址方式以及寄存器的使用等内容。ISA是硬件和软件之间的接口，决定了程序员如何编写程序以及编译器如何生成机器代码。
### 指令基本格式
一条指令通常包括操作码和操作数
[操作码字段] + [操作数字段]
- 操作码字段：指定要执行的操作类型，如加法、减法、数据传输等。
- 操作数字段：指定操作的对象，可以是寄存器、内存地址或立即数。
### 指令类型
1.一地址指令：指令中包含一个操作数地址，另一个操作数隐含在累加器中。
[OP][A1]
2.二地址指令：指令中包含两个操作数地址，结果存放在其中一个操作数地址中。
[OP][A1][A2]
3.三地址指令：指令中包含三个操作数地址，结果存放在第三个操作数地址中。
[OP][A1][A2][A3]
### 定长操作码和变长操作码
- 定长操作码：所有指令的长度相同，便于指令的译码和执行，但可能导致内存浪费。
- 变长操作码：指令长度不固定，可以根据需要使用不同长度的指令，节省内存空间，但增加了指令译码的复杂性。
#### 扩展操作码指令格式
扩展操作码指令格式通过引入前缀字节来扩展操作码的范围，从而支持更多的指令类型。通常，扩展操作码格式包括一个或多个前缀字节，后跟实际的操作码和操作数字段。
这种题都是每次留一位给下一个扩展操作码使用，所以扩展操作码的数量是2的n次方减1

对于前四位有15种扩展操作码

注意：扩展操作码的使用需要在指令译码阶段进行特殊处理，以正确识别和执行扩展指令。
短码不可以作为长码的前缀。

### 指令的操作类型
指令的操作类型主要包括以下几种：
1. 数据传送指令：用于在寄存器、内存和I/O设备之间传送数据，如MOV、LOAD、STORE等。
2. 算术运算指令：用于执行基本的算术运算，如加法、减法、乘法和除法，如ADD、SUB、MUL、DIV等。
3. 逻辑运算指令：用于执行逻辑运算，如与、或、非等，如AND、OR、NOT等。
4. 控制转移指令：用于改变程序的执行顺序，如跳转、调用和返回等，如JMP、CALL、RET等。
5. 比较指令：用于比较两个操作数的大小关系，并设置相应的标志位，如CMP等。
6. 位操作指令：用于对数据的位进行操作，如移位、旋转等，如SHL、SHR、ROL、ROR等。

### 指令的寻址方式

指令的寻址方式是指在指令中如何指定操作数的位置。常见的寻址方式包括：

1. **立即寻址**：操作数直接包含在指令中。→ EA = 指令中的操作数字段  
2. **直接寻址**：指令中包含操作数的内存地址。→ EA = A  
3. **间接寻址**：指令中包含一个地址，该地址指向操作数的实际存放位置。→ EA = (A)  
4. **寄存器寻址**：操作数存放在寄存器中，指令中指定寄存器编号。→ EA = (Ri)  
5. **寄存器间接寻址**：指令中指定一个寄存器，该寄存器中存放操作数的内存地址。→ EA = (Ri)  
6. **相对寻址**：操作数的地址由程序计数器（PC）和指令中的偏移量相加得到。→ EA = (PC) + offset  
7. **基址寻址**：操作数的地址由基址寄存器的内容和指令中的偏移量相加得到。→ EA = (Base) + offset  
8. **变址寻址**：操作数的地址由变址寄存器的内容和指令中的偏移量相加得到。→ EA = (Index) + offset  
9. **堆栈寻址**：操作数存放在堆栈中，通常通过堆栈指针（SP）访问。→ EA = (SP)

### 基址 和 变址区别
| 特点 | 基址寻址 | 变址寻址 |
| :--- | :--- | :--- |
| 目的 | 通常用于访问数据结构，如数组和记录 | 通常用于访问数组元素 |
| 寄存器类型 | 使用基址寄存器（Base Register） | 使用变址寄存器（Index Register） |
| 计算方式 | 地址 = 基址寄存器 + 偏移量 | 地址 = 变址寄存器 + 偏移量(实际上是变址寄存器在偏) |
![基址寻址与变址寻址对比](/picture/jizu-addressing-modes.png)

### 程序的机器级代码表示

程序的机器级代码表示是指将高级语言编写的程序转换为计算机能够直接执行的机器码的过程。机器码是由二进制位组成的指令序列，每条指令对应特定的操作和操作数。程序的机器级代码表示通常包括以下几个方面：

### 常用汇编指令介绍
| 汇编指令 | 功能描述 |
| :--- | :--- |
| MOV | 数据传送指令，将数据从一个位置复制到另一个位置 |
| ADD | 算术运算指令，执行加法操作 |
| SUB | 算术运算指令，执行减法操作 |
| MUL | 算术运算指令，执行乘法操作 |
| DIV | 算术运算指令，执行除法操作 |
| AND | 逻辑运算指令，执行按位与操作 |
| OR | 逻辑运算指令，执行按位或操作 |

### MIPS 指令格式
MIPS 指令集采用三种基本的指令格式：R 型指令、I 型指令和 J 型指令。
1. R 型指令（寄存器型指令）：用于寄存器之间的运算操作。
格式：| opcode (6 bits) | rs (5 bits) | rt (5 bits  ) | rd (5 bits) | shamt (5 bits) | funct (6 bits) |
2. I 型指令（立即数型指令）：用于数据传送和立即数运算。
格式：| opcode (6 bits) | rs (5 bits) | rt (5 bits) | immediate (16 bits) |
3. J 型指令（跳转型指令）：用于无条件跳转操作。
格式：| opcode (6 bits) | address (26 bits) | 

### MIPS指令
MIPS的内存空间的编址单位是字节，但它是按字寻址的。
这意味着每条指令占4个字节，地址必须是4的倍数。

MIPS指令集是精简指令集计算机（RISC）的典型代表，具有指令格式简单、执行速度快等特点。以下是一些MIPS特点和易错点：
1. 所有指令长度均为32位，便于指令的译码和执行。
2. 寄存器数量有限，只有32个通用寄存器（$0-$31），其中$0寄存器恒为0。
3. 使用延迟槽（Delay Slot）技术，在跳转指令后紧跟一条指令，以提高流水线效率。
4. MIPS采用大端字节序（Big-endian），即高位字节存放在低地址处。
5. MIPS指令中的立即数通常为16位，有符号扩展时需要注意符号位的处理。
6. 跳转指令的目标地址是通过将指令地址的高4位与跳转地址拼接而成的，需要注意地址计算方式。
7. MIPS指令中使用的偏移量通常以字为单位，需要乘以4才能得到字节地址。
8.J型指令跳转的地址是伪地址，需要左移两位再与PC的高4位拼接形成实际地址。做题的时候跳转地址除以4=伪地址。J型只能跳转到当前PC256MB范围内。
9.B型指令的分支地址是相对于下一条指令的地址计算的，需要注意偏移量的符号扩展和乘以4的处理。

#### J型和B型
- J型指令用于无条件跳转，目标地址由指令中的26位地址字段向左移位成28位和当前PC的高4位拼接而成。J型指令可以跳转到当前PC所在的256MB范围内的任意地址。
$New\_PC = (PC+4)[31:28] \| (address \ll 2)$。这里面的26位是立即数无符号，左移两位变成28位，再和PC的高4位拼接成32位地址。
- B型指令用于有条件跳转，目标地址是通过将当前PC加上指令中的16位偏移量（符号扩展成32位后乘以4）计算得到的。B型指令的跳转范围较小，一般在当前PC前后128KB范围内
$New\_PC = (PC+4) + (SignExtend(offset) \ll 2)$。这里面的16位是有符号的，符号扩展成32位后左移两位再加上PC+4得到目标地址。

#### MIPS 指令类别与控制信号总表

| 指令类别 | 指令示例 | RegDst | ALUSrc | MemtoReg | RegWrite | MemRead | MemWrite | Branch | Jump | ALUOp |
|---------|---------|--------|--------|----------|----------|----------|-----------|--------|------|-------|
| R-type | add, sub, and | 1 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 10 |
| Load | lw | 0 | 1 | 1 | 1 | 1 | 0 | 0 | 0 | 00 |
| Store | sw | X | 1 | X | 0 | 0 | 1 | 0 | 0 | 00 |
| Branch | beq | X | 0 | X | 0 | 0 | 0 | 1 | 0 | 01 |
| Jump | j | X | X | X | 0 | 0 | 0 | 0 | 1 | XX |
| Immediate | addi | 0 | 1 | 0 | 1 | 0 | 0 | 0 | 0 | 00 |
| Immediate | ori | 0 | 1 | 0 | 1 | 0 | 0 | 0 | 0 | 11 |

#### 流水线MIPS的数据通路
流水线MIPS的数据通路在单周期MIPS的基础上进行了改进，以支持指令流水线的并行执行。主要增加了以下几个部分：
1. **流水线寄存器**：在各个流水线阶段之间增加了流水线寄存器，用于存储每个阶段的中间结果和控制信号。
2. **转发单元**：用于解决数据冒险问题，通过将后续指令所需的数据直接从流水线寄存器中转发到需要的阶段，避免等待数据写回寄存器堆。
3. **暂停单元**：用于处理控制冒险和数据冒险，通过暂停流水线的某些阶段，确保指令的正确执行。
4. **分支预测单元**：用于提高分支指令的执行效率，通过预测分支的结果，提前加载可能需要执行的指令。

对于同一个周期，寄存器写入操作发生在周期的开始，而寄存器读取操作发生在周期的中间。因此，在同一个周期内，写入的数据可以被读取到。

### 堆栈
堆栈（Stack）是一种后进先出（LIFO，Last In First Out）的数据结构，广泛应用于计算机系统中，用于存储临时数据、函数调用信息等。堆栈通常由一块连续的内存区域组成，通过堆栈指针（Stack Pointer，SP）来管理堆栈的顶端位置。
堆栈是从高地址向低地址增长的。
易错点：
1.堆栈的增长方向和数组相反，数组是从低地址向高地址增长的。
2.堆栈操作主要包括入栈（Push）和出栈（Pop）两种基本操作。入栈操作将数据压入堆栈顶端，出栈操作则从堆栈顶端弹出数据。
3.函数调用过程中，堆栈用于保存函数的返回地址、参数和局部变量等信息，确保函数调用的正确性和嵌套调用的支持。

### 大小端模式
大小端模式（Endianness）是指多字节数据在内存中的存储顺序。主要有两种模式：大端模式（Big-endian）和小端模式（Little-endian）。
1. **大端模式**：高位字节存放在低地址处，低位字节存放在高地址处。
2. **小端模式**：低位字节存放在低地址处，高位字节存放在高地址处。
易错点：大端/小端在跨平台或网络传输时需注意字节序转换；类型强转与指针访问时需注意对齐与解释方式。

---

## 【四】存储系统

### 存储器
可以从不同角度分类存储器：
1. 按存储介质分类：磁性存储器（如硬盘）、光学存储器（如光盘）、半导体存储器（如RAM、ROM）等。
2. 按存取方式分类：随机存取存储器（RAM）、只读存储器（ROM）等。
3. 按存储层次分类：寄存器、高速缓存（Cache）、主存储器（Main Memory）、辅助存储器（Secondary Storage）等。
4. 可保持性分类：易失性存储器（如RAM）、非易失性存储器（如ROM、硬盘）等。
#### 存储器的基本性能指标

（考试要求相对较低，了解即可。）
1. 存取时间：指从发出存储器读写请求到数据被读出或写入所需的时间。
2. 存储容量：指存储器能够存储的数据量，通常以字节（Byte）为单位。
3. 传输速率：指存储器在单位时间内能够传输的数据量，通常以字节每秒（B/s）为单位。

#### 多级存储器系统

多级存储器系统是指将存储器划分为多个层次，每个层次具有不同的存取速度和容量，以提高整体存储系统的性能。通常包括以下几个层次：
1. 寄存器（Registers）：位于CPU内部，速度最快但容量最小。
2. 高速缓存（Cache）：位于CPU和主存储器之间，速度较快，容量较小。
3. 主存储器（Main Memory）：直接与CPU连接，速度较慢，容量较大。
4. 辅助存储器（Secondary Storage）：如硬盘、固态硬盘等，速度最慢但容量最大。
多级存储器系统通过利用局部性原理（时间局部性和空间局部性）来提高数据访问的效率。当CPU需要访问数据时，首先在寄存器中查找，如果未命中则查找高速缓存，依此类推，直到找到所需数据或确定数据不存在。
#### 易错点随机存取和顺序存取的区别
| 存取方式 | 随机存取 | 顺序存取 |
| :--- | :--- | :--- |
| 访问方式 | 可以直接访问任意存储单元 | 必须按顺序访问存储单元 |
| 访问速度 | 速度较快 | 速度较慢 |  
| 典型存储器 | RAM（随机存取存储器） | 磁带等顺序存取设备 |
| 应用场景 | 需要频繁访问不同数据的场景 | 适合大批量顺序处理数据的场景 |

RAM（随机存取存储器）是一种允许在任意时间以相同速度访问任何存储单元的存储器。而顺序存取存储器则要求按照一定的顺序访问数据，通常用于磁带等设备。
ROM（只读存储器）是一种只能读取数据而不能写入数据的存储器，通常用于存储固化程序和数据。但是也是随机存取的，因为可以直接访问任意存储单元。

#### 主存储器

##### SRAM 和 DRAM 的区别
| 存储器类型 | SRAM（静态随机存取存储器） | DRAM（动态随机存取存储器） |
| :--- | :--- | :--- |
| 存储单元结构 | 由触发器组成，每个存储单元由多个晶体管构成 | 由电容和晶体管组成，每个存储单元由一个电容和一个晶体管构成 |
| 数据保持方式 | 静态保持数据，只要有电源供应 | 需要定期刷新电容中的电荷以保持数据 |
| 访问速度 | 速度较快 | 速度较慢 |
| 功耗 | 功耗较低 | 功耗较高 |
| 成本 | 成本较高 | 成本较低 |
| 地址线 | 行地址和列地址同时发送 行作行 列作列 | 行地址和列地址分开发送 复用 |
| 应用场景 | 用于高速缓存等对速度要求较高的场景 | 用于主存储器等对容量要求较高的场景 |
SRAM由于其结构复杂，速度快且功耗低，通常用于CPU的高速缓存。而DRAM由于其结构简单，容量大且成本低，通常用于计算机的主存储器。
##### ROM

ROM（只读存储器）是一种只能读取数据而不能写入数据的存储器，通常用于存储固化程序和数据。
EPROM（可擦除可编程只读存储器）是一种可以通过紫外线擦除数据并重新编程的存储器。EEPROM（电可擦除可编程只读存储器）是一种可以通过电信号擦除数据并重新编程的存储器。Flash存储器是一种特殊类型的EEPROM，可以以块为单位进行擦除和编程，具有更高的存储密度和更快的访问速度。
ROM和RAM的区别主要在于数据的可写性和存储方式。ROM只能读取数据，通常用于存储固化程序和数据，而RAM可以读写数据，通常用于存储临时数据和程序运行时的数据。ROM通常是非易失性的，而RAM通常是易失性的。前者断电后数据不丢失，后者断电后数据丢失。

##### 主存储器的基本组成

主存储器主要由以下几个部分组成：
1. **存储单元**：主存储器由多个存储单元组成，每个存储单元可以存储一个字节或多个字节的数据。
2. **地址总线**：用于传输存储单元的地址信息，以便CPU能够访问特定的存储单元。
3. **数据总线**：用于传输存储单元中的数据，以便CPU能够读写数据。
4. **控制信号**：用于控制主存储器的读写操作，包括读写使能信号、时钟信号等。

MAR和MDR位数与主存储器地址线和数据线的宽度有关。假设主存储器有2^n个存储单元，则地址线宽度为n位，因此MAR的位数为n位。假设每个存储单元存储m位数据，则数据线宽度为m位，因此MDR的位数为m位。地址线的位数决定了主存储器的最大寻址能力，而数据线的位数决定了每次读写操作的数据量。

##### 交叉编址

交叉编址是一种存储器地址分配方式，通常用于提高存储器的访问效率。它将存储器划分为多个独立的模块，每个模块具有独立的地址空间和数据总线。通过交叉编址，可以实现并行访问多个存储模块，从而提高存储器的整体性能。
交叉编址的实现通常包括以下几个步骤：
1. **存储器划分**：将存储器划分为多个独立的模块，每个模块具有独立的地址空间和数据总线。
2. **地址映射**：将逻辑地址映射到物理地址，以便CPU能够访问特定的存储模块。
3. **并行访问**：通过交叉编址，实现对多个存储模块的并行访问，从而提高存储器的整体性能。
交叉编址通常用于高性能计算机系统中，以满足对高速数据访问的需求。

做题时注意区分交叉编址和交叉存取。交叉存取是指在存储器中交替存储数据，以提高数据访问的效率，而交叉编址是指将存储器划分为多个独立的模块，以实现并行访问。

交叉存储器中数据的存放方式：
每个模块按模m方式存放数据，即第i个数据存放在第(i mod m)个模块中。高位交叉编制中高位地址线决定模块号，低位地址线决定模块内地址；低位交叉编址中低位地址线决定模块号，高位地址线决定模块内地址。

模块号=地址 mod 模块数

### 主存储器和CPU的连接
主存储器通过地址总线、数据总线和控制信号与CPU连接。地址总线用于传输存储单元的地址信息，数据总线用于传输存储单元中的数据，控制信号用于控制主存储器的读写操作。CPU通过这些连接与主存储器进行数据交换和指令执行。
![主存储器与CPU的连接](/picture/jizu-cpu-memory-connection.png)
#### 主存容量的扩展
1.位扩展法：增加地址线的数量，从而增加主存储器的地址空间。例如，将地址线从16位扩展到20位，可以将主存储器的容量从64KB扩展到1MB。
2.字扩展法：增加数据线的数量，从而增加每个存储单元的数据存储能力。例如，将数据线从8位扩展到16位，可以将每个存储单元的数据存储能力从1字节扩展到2字节。
3.字位同时扩展法：同时增加地址线和数据线的数量，从而同时增加主存储器的地址空间和每个存储单元的数据存储能力。例如，将地址线从16位扩展到20位，数据线从8位扩展到16位，可以将主存储器的容量从64KB扩展到2MB。

### 外部存储器
外部存储器是指计算机系统中用于长期存储数据和程序的存储设备，通常具有较大的存储容量和较低的存取速度。常见的外部存储器包括硬盘、固态硬盘、光盘、磁带等。外部存储器通过输入输出接口与计算机系统连接，实现数据的读写操作。
#### 磁盘存储器
磁盘存储器是一种常见的外部存储器，通常由多个磁盘片组成，通过磁头在磁盘表面读写数据。磁盘存储器具有较大的存储容量和较快的存取速度，广泛应用于计算机系统中。磁盘存储器的基本组成包括：
1. **磁盘片**：由多个圆形磁盘片组成，每个磁盘片表面覆盖有磁性材料，用于存储数据。
2. **磁头**：用于在磁盘片表面读写数据，通常由多个磁头组成，每个磁头对应一个磁盘片。
3. **驱动器**：用于驱动磁盘片旋转和控制磁头的移动，实现数据的读写操作。
4. **控制器**：用于管理磁盘存储器的读写操作，包括数据传输、错误检测和纠正等功能。
磁盘存储器的性能指标主要包括存取时间、传输速率和存储容量。存取时间包括寻道时间和旋转延迟，传输速率指单位时间内能够传输的数据量，存储容量指磁盘存储器能够存储的数据量。
#### 固态硬盘
固态硬盘（SSD）是一种基于闪存技术的外部存储器，具有较快的读写速度和较高的可靠性。与传统的磁盘存储器相比，固态硬盘没有机械部件，因此具有更低的延迟和更高的抗震能力。固态硬盘的性能指标主要包括读写速度、存储容量和寿命。

### Cache

#### Cache 基本概念
Cache（高速缓存）是一种位于CPU和主存储器之间的高速存储器，用于存储频繁访问的数据和指令。Cache利用局部性原理，提高数据访问的效率，减少CPU对主存储器的访问次数，从而提高计算机系统的整体性能。Cache通常分为一级缓存（L1 Cache）、二级缓存（L2 Cache）和三级缓存（L3 Cache），其中L1 Cache速度最快但容量最小，L3 Cache速度最慢但容量最大。
Cache的基本组成包括：
1. **缓存存储器**：用于存储频繁访问的数据和指令
2. **缓存控制器**：用于管理缓存存储器的读写操作，包括缓存命中和未命中的处理。
3. **地址映射机制**：用于将主存储器的地址映射到缓存存储器的地址。


Cache有SRAM组成，通常直接集成在CPU芯片内部，以提高访问速度。
#### 程序访问的局部性

程序在执行过程中，往往会频繁访问一小部分数据和指令，这种现象称为局部性原理。局部性原理主要包括两种类型：
1. **时间局部性**：如果某个数据或指令在某一个时间段内被访问过，那么在不久的将来它很可能会再次被访问。多次访问同一变量体现时间局部性，做题技巧：循环结构中频繁访问的变量体现时间局部性，比如for循环中的控制变量i。比如temp=arr[i]; i++; temp=arr[i]; i++; 这里的i就体现了时间局部性。

2. **空间局部性**：如果某个数据或指令在某一个地址被访问过，那么在不久的将来，其相邻地址的数据或指令也很可能会被访问。做题技巧：空间局部性通常与顺序访问有关。顺序访问数组体现空间局部性，随机访问数组则不体现空间局部性。

#### Cache 的基本原理

Cache（高速缓存）是一种位于 CPU 和主存储器之间的高速存储器，用于存储频繁访问的数据和指令。Cache利用局部性原理，提高数据访问的效率，减少CPU对主存储器的访问次数，从而提高计算机系统的整体性能。
![高速缓冲存储器的工作原理](/picture/jizu-cache-principle.png)
Cache的基本工作原理包括以下几个步骤：
1. **地址映射**：当CPU需要访问某个数据时，首先将该数据的主存地址通过地址映射机制转换为Cache地址，以确定数据是否存储在Cache中。
2. **缓存查找**：根据映射得到的Cache地址，在Cache存储器中查找该数据。如果数据存在于Cache中，称为缓存命中（Cache Hit）；如果数据不存在于Cache中，称为缓存未命中（Cache Miss）。
3. **数据传输**：如果发生缓存命中，直接从Cache中读取数据并返回给CPU；如果发生缓存未命中，则从主存储器中读取数据，并将其存储到Cache中，然后再返回给CPU。
4. **替换策略**：当Cache已满且需要存储新的数据时，采用替换策略决定将哪个数据从Cache中移除，以腾出空间存储新数据。常见的替换策略包括最近最少使用（LRU）、先进先出（FIFO）和随机替换等。

#### Cache的映射方式
Cache的映射方式主要有三种：直接映射（Direct Mapping）、全相联映射（Fully Associative Mapping）和组相联映射（Set Associative Mapping）。
1. **直接映射**：每个主存块只能映射到Cache中的一个特定位置。优点是实现简单，缺点是容易发生冲突，导致缓存未命中率较高。直接映射的关系可以定义为：
   Cache行号 = 主存块号 mod Cache行数
   ![Cache与主存直接映射](/picture/jizu-cache-direct-mapping.png)
直接映射的地址结构：
| 标记（Tag） | 行号（Index） | 块内地址（Block Offset） |
| :--- | :--- | :--- |
2. **全相联映射**：每个主存块可以映射到Cache中的任何位置。优点是减少了冲突，缺点是实现复杂且查找速度较慢。全相联映射的地址结构：
![Cache与主存全相联映射](/picture/jizu-cache-full-associative.png)
| 标记（Tag） | 块内地址（Block Offset） |
访存过程中需要比较所有Cache行的标记，以确定数据是否存在于Cache中。

3. **组相联映射**：将Cache划分为多个组，每个主存块只能映射到某一组中的任意位置。优点是兼顾了直接映射和全相联映射的优点，缺点是实现复杂度介于两者之间。
x路组相联映射意味着一组里面有x行Cache。

基本思想

将 Cache 分成 **Q 个大小相等的组**，  
每个主存块 **只能映射到固定的一个 Cache 组**，  
但可以放入该组中的 **任意一行**。

- **组间**：采用 *直接映射*
- **组内**：采用 *全相联映射*

组相联映射是 **直接映射与全相联映射的折中方案**

当 **Q = 1** 时，退化为 **全相联映射**
- 当 **Q = Cache 行数** 时，退化为 **直接映射**
- **路数越大（每组 Cache 行数越多）**
  - 块冲突概率越低
  - 硬件复杂度越高
- 选择合适的路数，可使成本接近直接映射，
  而性能接近全相联映射

路数的定义

- 若每组有 **r 行 Cache**，称为 **r 路组相联**
- 图中每组有 **2 行 Cache**
  - → **2 路组相联映射**
组相联映射的地址结构：
| 标记（Tag） | 组号（Set Index） | 块内地址（Block Offset） |
Cache 组号 = 主存块号 mod Cache 组数（Q）


访存过程：
1. 根据主存地址的组号部分确定访问的 Cache 组
2. 在该组内的所有 Cache 行中比较标记部分，判断数据是否存在于 Cache 中 （一个组有R行，则需要R次比较，有R个比较器）
3. 若命中，则从对应的 Cache 行中读取数据；若未命中，则从主存中读取数据，并将其存储到该组的某一行中（根据替换策略选择行）
4. 若不相等或者有效位为0，则未命中，需从主存调入数据
5. 此时CPU从主存中读出该地址所在的一块信息块送到对应的Cache行，并更新该行的标记和有效位

组相联时Cache的容量计算：总容量 = 数据容量 + 控制信息容量
每一行 Cache 包含：

[ Data | Tag | Valid | Dirty | (可选替换位) ]


Cache 总容量=Cache 行数×(块大小+Tag 位数+状态位数)
其中状态位数包括有效位（Valid Bit）、修改位（Dirty Bit）和可选的替换位（Replacement Bits）。

#### LRU替换算法
LRU（Least Recently Used，最近最少使用）替换算法是一种常用的缓存替换策略，用于决定在缓存已满时，应该将哪个缓存块替换出去。LRU算法的基本思想是，当需要替换一个缓存块时，选择最近最少被使用的那个块进行替换。这样可以最大限度地保留那些最近被频繁访问的数据，从而提高缓存的命中率。
LRU算法的实现：
**重点**
LRU 计数器在硬件逻辑上维护的就是一个优先级队列（Priority Queue）
队列的结构
队头 (MRU, Most Recently Used)：计数值为 0 的块。这是当前最“火”的数据，刚刚被宠幸过。

队尾 (LRU, Least Recently Used)：计数值为 n-1 的块。这是最“冷”的数据，如果有人要进来，它第一个被踢走。

2. 队列的动态维护（插队逻辑）
这个队列的维护规则非常像**“插队”**：

命中 (Hit) = “老员工插队到第一名”
当 CPU 访问了队列中间的某个块时：

该块立刻从原位置脱离，直接插到队头（计数器变 0）。

原本排在它前面的所有人，被迫全部向后退一步（计数器加 1）。

原本排在它后面的人，位置不受影响。

未命中 (Miss) = “末位淘汰”
当 CPU 访问的数据不在队列里时：

队尾的那个人（计数器最大者）被直接踢出队列。

新成员作为“新人”直接插到队头（计数器变 0）。

队列里剩下的所有人，全部向后退一步（计数器加 1）。

#### Cache的一致性问题
Cache一致性问题是指在多处理器系统中，由于每个处理器都有自己的Cache，当一个处理器修改了某个数据时，其他处理器的Cache中可能仍然存储着该数据的旧值，导致数据不一致的问题。为了解决Cache一致性问题，通常采用以下两种方法
1. **写直达（Write Through）**：当一个处理器修改了Cache中的数据时，同时将该数据写回到主存储器中。这样可以确保主存储器中的数据始终是最新的，但会增加写操作的延迟和总线带宽的压力。
2. **写回（Write Back）**：当一个处理器修改了Cache中的数据时，不立即将该数据写回到主存储器中，而是将其标记为“脏”（Dirty）。只有当**该数据被替换出Cache**时，才将其写回到主存储器中。这样可以减少写操作的次数，提高系统性能，但需要额外的机制来确保数据的一致性。

#### 写操作不命中的处理策略
当写操作发生不命中时，通常有以下几种处理策略：
1. **写分配（Write Allocate）**：当写操作不命中时，先将对应的数据块从主存储器中读入Cache，然后再进行写操作。这样可以利用局部性原理，提高后续对该数据块的访问效率。常与写回策略结合使用。
2. **不写分配（No Write Allocate）**：当写操作不命中时，直接将数据写入主存储器，而不将数据块读入Cache。这样可以减少Cache的污染，适用于写操作较多且访问局部性较差的场景。常与写直达策略结合使用。

### 虚拟存储器

#### 基本概念
虚拟存储器是一种将主存储器和辅助存储器结合使用的存储管理技术，通过将程序的逻辑地址空间映射到物理地址空间，实现对大容量存储器的有效利用。虚拟存储器允许程序使用比实际主存储器更大的地址空间，从而提高了程序的灵活性和系统的整体性能。
![虚拟存储器的三个地址空间](/picture/jizu-virtual-memory-spaces.png)
CPU使用虚地址时，先判断这个虚地址对应的内容是否已经装入主存中。若在主存中，进行地址变换，CPU直接访问主存；若不在主存中，则发生缺页异常，由操作系统将所需页从外存调入主存，然后再进行地址变换，CPU访问主存。
#### 虚拟存储器为什么只能用回写法
虚拟存储器通常只能使用写回法（Write Back）而不能使用写直达法（Write Through），主要有以下几个原因：
1. **性能考虑**：虚拟存储器的主要目的是提高系统的性能，而写直达法会增加写操作的延迟和总线带宽的压力，降低系统的整体性能。写回法可以减少写操作的次数，提高系统性能。
2. **页表管理**：虚拟存储器使用页表来管理虚拟地址和物理地址之间的映射关系。写直达法需要频繁地更新页表，而写回法只在页面被替换出Cache时才更新页表，减少了页表的更新频率。
3. **数据一致性**：虚拟存储器需要确保数据的一致性，而写回法可以通过标记“脏页”来跟踪哪些页面被修改过，从而在页面被替换出Cache时将其写回到主存储器中，确保数据的一致性。

#### 页式虚拟存储器
页式虚拟存储器是一种将虚拟地址空间划分为固定大小的页面（Page），并将物理地址空间划分为相同大小的页框（Frame）的存储管理技术。通过页表（Page Table）实现虚拟地址到物理地址的映射，从而实现对大容量存储器的有效利用。
##### 页表
页表是页式虚拟存储器中的关键数据结构，用于存储虚拟页面和物理页框之间的映射关系。每个进程都有自己的页表，操作系统通过页表来管理虚拟地址空间和物理地址空间之间的映射。
页表项（Page Table Entry，PTE）通常包含以下信息：
1. **有效位（Valid Bit）**：指示该页表项是否有效，即对应的虚拟页面是否已经加载到主存中。
2. **物理页框号（Frame Number）**：指示该虚拟页面对应的物理页框号。
3. **访问权限（Access Permissions）**：指示该虚拟页面的访问权限，如只读、读写等。
4. **修改位（Dirty Bit）**：指示该页面是否被修改过。
5. **使用位（Reference Bit）**：指示该页面是否被访问过。
##### 页和块的区别
页（Page）和块（Block）是存储管理中的两个重要概念，虽然它们在某些方面有相似之处，但也存在一些区别。
1. **定义**：
   - 页（Page）：页是虚拟存储器中的基本单位，指的是虚拟地址空间被划分为的固定大小的块。每个页通常具有相同的大小，如4KB、8KB等。
   - 块（Block）：块是主存储器或Cache中的基本单位，指的是物理地址空间被划分为的固定大小的块。块的大小通常与页的大小相同，以便于页与块之间的映射。
2. **作用**：
   - 页（Page）：页用于管理虚拟地址空间，实现虚拟地址到物理地址的映射，从而实现对大容量存储器的有效利用。
   - 块（Block）：块用于管理主存储器或Cache中的数据存储，提高数据访问的效率。
3. **存储位置**：
   - 页（Page）：页存储在辅助存储器（如硬盘）中，当需要访问某个页时，操作系统会将其从辅助存储器加载到主存储器中。
   - 块（Block）：块存储在主存储器或Cache中，CPU可以直接访问块中的数据。
##### 地址变换
地址变换是指将虚拟地址转换为物理地址的过程。在页式虚拟存储器中，地址变换通常包括以下几个步骤：
1. **虚拟地址划分**：将虚拟地址划分为虚拟页号（VPN）和页内偏移（Offset）。虚拟页号用于索引页表，页内偏移用于确定页面内的具体位置。
2. **页表查找**：根据虚拟页号在页表中查找对应的页表项。如果页表项的有效位为1，表示该虚拟页面已经加载到主存中；如果有效位为0，表示发生缺页异常，需要将页面从外存调入主存。
3. **物理地址计算**：根据页表项中的物理页框号和页内偏移，计算出对应的物理地址。
物理地址 = [ 物理页框号 | 页内偏移 ]

##### TLB（快表）
TLB（Translation Lookaside Buffer，快表）是一种用于加速地址变换过程的高速缓存，存储了最近使用的虚拟页号和物理页框号之间的映射关系。当CPU需要进行地址变换时，首先在TLB中查找对应的映射关系，如果命中则直接获取物理地址；如果未命中则需要访问页表进行地址变换。
TLB的工作过程包括以下几个步骤：
1. **TLB查找**：根据虚拟页号在TLB中查找对应的映射关系。如果命中则直接获取物理页框号；如果未命中则需要访问页表。
2. **页表访问**：如果TLB未命中，则根据虚拟页号在页表中查找对应的页表项，获取物理页框号。
3. **TLB更新**：将新获取的虚拟页号和物理页框号的映射关系存储到TLB中，以便后续访问加速。
TLB的性能指标主要包括命中率和访问时间。高命中率可以显著提高地址变换的效率，减少对页表的访问次数，从而提高系统的整体性能。

##### TLB的硬件实现 与cache的比较
TLB和Cache在硬件实现上有一些相似之处，但也存在一些区别。两者都是高速缓存，用于存储最近使用的数据，以提高访问速度。以下是TLB和Cache在硬件实现上的比较：
1. **存储内容**：
   - TLB：存储虚拟页号和物理页框号之间的映射关系。
   - Cache：存储频繁访问的数据和指令。
2. **地址映射**：
   - TLB：用于加速虚拟地址到物理地址的转换过程。
    - Cache：用于加速数据访问过程。
3. **查找方式**：
   - TLB：通常采用全相联映射方式，以提高命中率。
   - Cache：可以采用直接映射、全相联映射或组相联映射方式。
4. **大小和结构**：
   - TLB：通常较小，包含几十到几百个条目，结构简单。
   - Cache：通常较大，包含数KB到数MB的存储空间，结构复杂。
5. **访问时间**：
   - TLB：访问时间非常短，通常在一个CPU时钟周期内完成
    - Cache：访问时间较短，但通常比TLB稍长，可能需要几个CPU时钟周期。
##### TLB映射方式 地址划分 标记字段的分析
TLB的映射方式通常采用全相联映射方式，以提高命中率。TLB的地址划分包括虚拟页号（VPN）和页内偏移（Offset）。虚拟页号用于索引TLB，页内偏移用于确定页面内的具体位置。
TLB的tag字段用于存储虚拟页号，以便在TLB查找过程中进行比较。
TLB的标记字段通常包含以下信息：
1. **虚拟页号（VPN）**：用于标识虚拟页面的唯一标识符。
2. **物理页框号（Frame Number）**：用于标识对应的物理页框的唯一标识符。
3. **有效位（Valid Bit）**：指示该TLB条目是否有效。
4. **访问权限（Access Permissions）**：指示该虚拟页面的访问权限，如只读、读写等。
5. **其他状态位**：如修改位（Dirty Bit）、使用位（Reference Bit）等。

##### TLB Cache Page的缺失分析
![TLB与Cache缺页缺失分析](/picture/jizu-tlb-cache-miss.png)
解题套路：page缺失其他两个都缺 因为page缺失说明主存没有，TLB和cache都不可能有。

TLB命中不命中都不会影响page缺失的判断，因为page缺失是指主存中没有对应的页，而TLB和Cache只是加速访问的缓存层次。



## 常见问题和易错点分析
1.Cache行的大小和命中率之间有什么关系？
Cache行的大小对命中率有显著影响。较大的Cache行可以利用空间局部性原理，减少缓存未命中的概率，从而提高命中率。然而，过大的Cache行可能导致缓存污染（Cache Pollution），因为加载不必要的数据会占用宝贵的缓存空间，反而降低命中率。因此，选择合适的Cache行大小是权衡命中率和缓存利用率的关键。
2.为什么虚拟存储器只能使用写回法而不能使用写直达？
虚拟存储器通常只能使用写回法（Write Back）而不能使用写直达法（Write Through），主要有以下几个原因：
- 性能考虑：写直达法会增加写操作的延迟和总线带宽的压力，降低系统的整体性能。写回法可以减少写操作的次数，提高系统性能。
- 页表管理：虚拟存储器使用页表来管理虚拟地址和物理地址之间的映射关系。写直达法需要频繁地更新页表，而写回法只在页面被替换出Cache时才更新页表，减少了页表的更新频率。
- 数据一致性：虚拟存储器需要确保数据的一致性，而写回法可以通过标记“脏页”来跟踪哪些页面被修改过，从而在页面被替换出Cache时将其写回到主存储器中，确保数据的一致性。

3.Cache总容量和映射关系有什么关系？
Cache总容量与映射关系密切相关。Cache的总容量决定了可以存储的数据量，而映射关系（如直接映射、全相联映射和组相联映射）影响了数据在Cache中的存储方式和访问效率。不同的映射方式对Cache的利用率和命中率有不同的影响。例如，直接映射简单但容易发生冲突，而全相联映射灵活但实现复杂。组相联映射则在两者之间取得平衡。因此，在设计Cache时，需要综合考虑总容量和映射关系，以优化性能

![Cache行与三种映射方式](/picture/jizu-cache-mapping-comparison.png)


4.页和块的区别是什么？
页（Page）和块（Block）是存储管理中的两个重要概念，虽然它们在某些方面有相似之处，但也存在一些区别。
- 定义：
  - 页（Page）：页是虚拟存储器中的基本单位，指的是虚拟地址空间被划分为的固定大小的块。每个页通常具有相同的大小，如4KB、8KB等。
  - 块（Block）：块是主存储器或Cache中的基本单位，指的是物理地址空间被划分为的固定大小的块。块的大小通常与页的大小相同，以便于页与块之间的映射。

5.Cache行包括哪些部分？
Cache行通常包括以下几个部分：
1.Cache块数据（Data）：存储实际的数据内容。
2.标记（Tag）：用于标识该Cache行对应的主存地址。
3.有效位（Valid Bit）：指示该Cache行是否包含有效数据。
4.修改位（Dirty Bit）：指示该Cache行中的数据是否被修改过。
5.替换位（Replacement Bits）：用于实现替换策略，如LRU等。

所以Cache 以行为单位存储数据。
每条 Cache 行不仅包含一个数据块，还包含对应的标记位（Tag）及状态位。
访问 Cache 时，通过比较 Cache 行中的 Tag 与地址中的 Tag 判断是否命中。

6.TLB和Cache有什么区别？
TLB（Translation Lookaside Buffer，快表）和Cache（高速缓存）都是用于提高数据访问速度的高速存储器，但它们在功能和用途上有一些区别：
- 功能：
  - TLB：用于加速虚拟地址到物理地址的转换过程，存储最近使用的虚拟页号和物理页框号之间的映射关系。
  - Cache：用于存储频繁访问的数据和指令，提高数据访问的效率。

---

## 【五】中央处理器

### CPU 的功能和基本结构
### 功能
中央处理器（Central Processing Unit，CPU）是计算机的核心部件，负责执行计算机指令和处理数据。它的主要功能包括：
1. **指令执行**：CPU从内存中获取指令，解释并执行这些指令。
2. **数据处理**：CPU对数据进行算术和逻辑运算。          
3. **控制协调**：CPU协调计算机各个部件的工作，确保数据和指令的正确流动。
4. **中断处理**：CPU响应外部设备的中断请求，进行相应的处理。
### 基本结构
CPU的基本结构主要包括以下几个部分： 
1. 运算器（Arithmetic Logic Unit，ALU）：负责执行算术和逻辑运算。
2. 控制器（Control Unit，CU）：负责指令的解码和执行的控制。
3. 寄存器（Registers）：用于临时存储数据和指令，提高数据处理速度。
4. 缓存（Cache）：高速存储器，用于存储频繁使用的数据和指令，减少访问内存的时间。
5. 总线接口单元（Bus Interface Unit，BIU）：负责与内存 和其他外设进行数据交换。
#### CPU的寄存器
CPU中的寄存器是高速存储单元，用于临时存储数据和指令。

##### 寄存器分类
1. **用户可见寄存器**：可对这类寄存器编程，以减少对主存储器的访问次数。
   - 通用寄存器组（含基址/变址寄存器）
   - 程序状态字寄存器 (PSW)
   - 程序计数器 (PC)
2. **用户不可见寄存器**：对用户透明，不可对这类寄存器编程，由控制部件使用。
   - 存储器地址寄存器 (MAR)
   - 存储器数据寄存器 (MDR)
   - 指令寄存器 (IR)
   - 暂存寄存器
   - 累加寄存器
   - 移位寄存器

##### 1. 运算器中的寄存器
1. **通用寄存器组 (GPRs)**：用于存放操作数（包括源操作数、目的操作数及中间结果）和各种地址信息等，如 AX、BX、CX、DX、SP 等。SP 是堆栈指针，用于指示栈顶的地址。
2. **累加寄存器 (ACC)**：是一个通用寄存器，用于暂时存放 ALU 运算的结果。
3. **移位寄存器 (SR)**：不但可用来存放操作数，而且在控制信号的作用下，寄存器中的数据可根据需要向左或向右移位。
4. **暂存寄存器**：用于暂存从数据总线或通用寄存器送来的操作数，以便在取出下一个操作数时将其同时送入 ALU。对应用程序员是透明的（不可见）。
5. **程序状态字 (PSW) 寄存器**：保留由算术/逻辑运算指令或测试指令的运行结果而建立的各种状态信息，如溢出标志 (OF)、符号标志 (SF)、零标志 (ZF)、进位标志 (CF) 等。

##### 2. 控制器中的寄存器
1. **程序计数器 (PC)**：用于指出欲执行指令在主存储器中的存放地址。
   - 若 PC 和主存储器均按字节编址，则 PC 的位数等于主存储器地址位数。
   - 具有自动加 1 的功能（这里的“1”是指一条指令的字节数）。
   - 当遇到转移类指令时，PC 的新值由指令计算得到。
2. **指令寄存器 (IR)**：用于保存当前正在执行的指令，IR 的位数等于指令字长。
##### 常考点：寄存器的可见性
| 类别 | 寄存器 | 特点 |
| :--- | :--- | :--- |
| **用户可见** (不透明) | 通用寄存器 (GPRs)、程序计数器 (PC)、程序状态寄存器 (PSR/PSW) | 程序员编程时需要直接操作或根据其状态做决策。 |
| **用户不可见** (透明) | 指令寄存器 (IR)、存储器地址寄存器 (MAR)、存储器数据寄存器 (MDR)、暂存寄存器 | 这些是 CPU 内部硬件逻辑自动调用的，程序员无法通过指令直接访问。 |


#### 控制器的功能和工作原理
控制器是 CPU 的核心部分，负责指令的解码和执行的控制。它的主要功能包括：
1. **指令获取**：从内存中获取指令并将其送入指令寄存器 (IR)。
2. **指令解码**：解释指令的含义，确定需要执行的操作。
3. **控制信号生成**：根据指令的要求，生成相应的 控制信号，协调 CPU 各个部件的工作。
4. **执行控制**：控制指令的执行过程，包括数据的传输和运算的进行。
##### 工作原理
控制器的工作原理通常包括以下几个步骤：
1. **取指令周期**：控制器从程序计数器 (PC) 指定的内存地址获取指令，并将 PC 加 1 指向下一条指令。
2. **指令解码周期**：将获取的指令送入指令寄存器 (IR)，并对指令进行解码，确定操作类型和操作数位置。
3. **执行周期**：根据解码结果，生成相应的控制信号，协调 ALU、寄存器和内存等部件完成指令的执行。 

##### 硬布线控制器
硬布线控制器通过固定的逻辑电路实现指令的解码和控制信号的生成。它具有执行速度快、响应时间短的优点，但缺乏灵活性，难以适应新的指令集。RISC 处理器通常采用硬布线控制器。
##### 微程序控制器
微程序控制器通过存储在控制存储器中的微指令来实现指令的解码和控制信号的生成。它具有较高的灵活性，易于修改和扩展指令集，但执行速度相对较慢。CISC 处理器通常采用微程序控制器。
使用ROM存储微程序的控制器称为只读存储器控制器，使用RAM存储微程序的控制器称为可编程控制器。
##### 易错点 主存储器和控制存储器的区别
| 存储器类型 | 主存储器 | 控制存储器 |
| :--- | :--- | :--- |
| 作用 | 存储程序和数据 | 存储微程序 |
| 存储内容 | 用户程序和数据 | 控制指令（微指令） |
| 可见性 | 对用户可见 | 对用户不可见 |
| 实现方式 | 通常为 RAM | 通常为 ROM  |

存放微指令的控制存储器的单元地址称为微地址，存放微指令的单元称为微指令字。微指令字的长度称为微指令字长。

程序与微程序的区别：程序是指令的有序集合。微程序是微指令的有序集合。

应注意区分一下寄存器：
1.地址寄存器：
2.微指令地址寄存器：
3.指令寄存器：
4.微指令寄存器：

###### 微程序控制器的组成和工作过程
微程序控制器主要由以下几个部分组成：
1. **微指令寄存器 (CMDR)**：用于存放当前执行的微指令。
2. **微地址寄存器 (CMAR)**：用于存放当前微指令的地址。
3. **控制存储器 (Control Store)**：存放微指令的存储器。
4. **微指令译码器**：将微指令译码为具体的控制信号。
##### 工作过程
微程序控制器的工作过程通常包括以下几个步骤：
1. **微指令获取**：从控制存储器中获取当前微指令，并将其送入微指令寄存器 (CMDR)。
2. **微指令解码**：将微指令送入微指令译码器，生成相应的控制信号。
3. **执行控制**：根据微指令的要求，协调 CPU 各个部件的工作，完成指令的执行。
4. **微指令地址更新**：根据微指令的控制字段，更新微地址寄存器 (CMAR) 的值，指向下一条微指令的地址。
5. 重复上述过程，直到完成整个指令的执行。

微指令通常包括以下几种类型：
1. **顺序微指令**：按顺序执行下一条微指令
2. **跳转微指令**：根据条件跳转到指定地址的微指令
3. **调用微指令**：调用子程序的微指令
4. **返回微指令**：从子程序返回的微指令

### 异常和中断
#### 异常
异常是指在程序执行过程中，由于某种原因导致程序无法继续正常执行的情况。异常通常由以下几种原因引起：
1. **硬件故障**：如内存错误、设备故障等。
2. **软件错误**：如非法指令、算术溢出等。
3. **外部事件**：如电源中断、时钟中断等。
当异常发生时，CPU 会暂停当前程序的执行，保存程序状态，并转移到异常处理程序进行处理。处理完成后，CPU 会恢复程序状态，继续执行原程序。
##### 异常的分类
异常可以分类为以下几种类型：
1.故障（Faults）：在指令执行前检测到的问题，可以通过重试指令来恢复。例如页面错误。
2.陷阱（Traps）：在指令执行后检测到的问题，通常用于调试和系统调用。预先设置的陷阱点。例如设置断点。
3.终止（Aborts）：严重错误，无法恢复，通常导致程序终止。如控制器出错。随机发生的硬件故障。

前两者属于程序性异常，可以通过异常处理程序恢复执行；而终止属于非程序性异常，通常无法恢复执行。

#### 中断
中断是指计算机系统在运行过程中，由外部设备或内部事件发出的请求，要求 CPU 暂停当前程序的执行，转而处理该请求的机制。中断通常由以下几种来源引起：
1. **外部设备中断**：如键盘输入、鼠标点击、网络数据到达等。
2. **定时器中断**：由系统定时器产生，用于实现多任务调度等功能。
3. **软件中断**：由程序执行特定指令触发，如系统调用。
当中断发生时，CPU 会暂停当前程序的执行，保存程序状态，并转移到中断处理程序进行处理。处理完成后，CPU 会恢复程序状态，继续执行原程序。
#### 中断分类
可屏蔽中断（Maskable Interrupts）：可以通过设置中断屏蔽位来禁止或允许的中断类型。通常用于外部设备中断。
不可屏蔽中断（Non-Maskable Interrupts, NMI）：无法被屏蔽的中断类型，通常用于处理紧急情况，如硬件故障。

#### 异常和中断响应过程
CPU在执行过程中，当检测到异常或接收到中断请求时，会按照以下步骤进行响应：
1. 关中断：禁止其他中断请求，确保当前异常或中断处理的完整性。
2. 保存现场：将当前程序的状态（如PC、PSW等寄存器内容）保存到栈或预定的内存区域。保存断点以及程序状态
3. 确定处理程序地址：根据异常或中断类型，确定相应的处理程序入口地址。
4. 转移控制权：将程序计数器 (PC) 设置为处理程序的入口地址，开始执行处理程序。
5. 恢复现场：处理程序执行完毕后，恢复之前保存的程序状态。
6. 返程执行：继续执行被中断的程序。

##### 易错点
外部中断和内部中断的区别
| 特点 | 外部中断 | 内部中断（异常） |
| :--- | :--- | :--- |
| 触发源 | 由外部设备或事件触发 | 由 CPU 内部事件触发 |
| 处理时机 | 可在任何时间发生 | 通常在指令执行过程中发生 |
| 处理方式 | 通过中断向量表定位处理程序 | 通过异常向量表定位处理程序 |
| 可屏蔽性 | 可屏蔽中断可被禁止 | 通常不可屏蔽 |
页缺失属于内部异常中的故障，可以通过重试指令来恢复执行。需要返回发生故障的指令重新执行。
而外部异常如I/O中断，则不需要返回到发生中断的指令处继续执行，而是从中断处理程序执行完后，继续执行被中断的指令的下一条指令。（这个知识点考过）

### 单周期CPU
单周期 CPU 是指在一个时钟周期内完成一条指令的取指、译码和执行的 CPU 设计。单周期 CPU 的主要特点包括：
1. **简单性**：单周期 CPU 的设计相对简单，易于理解和实现。
2. **低效率**：由于所有指令都必须在一个时钟周期内完成，时钟周期必须足够长以适应最复杂的指令，导致整体性能较低。
3. **高资源消耗**：为了在一个周期内完成所有操作，单周期 CPU 需要更多的硬件资源，如多条数据通路和控制信号。
#### 单周期 CPU 的结构
单周期 CPU 的基本结构包括以下几个部分：
1. **指令寄存器 (IR)**：用于存放当前执行的指令。
2. **程序计数器 (PC)**：用于存放下一条指令的地址。
3. **寄存器堆 (Register File)**：用于存放通用寄存器的数据。
4. **算术逻辑单元 (ALU)**：用于执行算术和逻辑运算。
5. **数据通路 (Data Path)**：连接各个部件的数据传输路径。
6. **控制单元 (Control Unit)**：生成控制信号，协调各个部件的工作。
#### 单周期 CPU 的工作过程
单周期 CPU 的工作过程通常包括以下几个步骤：
1. **取指令**：从内存中获取指令，并将其存入指令寄存器 (IR)。
2. **译码**：将指令送入控制单元，生成相应的控制信号。
3. **执行**：根据控制信号，执行指令所要求的操作，如算术运算或数据传输。
4. **写回**：将运算结果写回寄存器堆或内存。
#### 单周期 CPU 的控制信号
单周期 CPU 的控制信号用于协调各个部件的工作，确保指令能够正确执行。常见的控制信号包括：
> - RegWrite：是否写寄存器
> - RegDst：目的寄存器选择（rd / rt）
> - ALUSrc：ALU 第二操作数来源
> - ALUOp：ALU 操作类型
> - MemRead / MemWrite：数据存储器读写
> - MemtoReg：写回数据来源
> - Branch：条件分支控制
> - Jump：无条件跳转



### 指令流水线
指令流水线是一种提高 CPU 执行效率的技术，通过将指令的执行过程划分为多个阶段，并使多个指令在不同阶段同时进行处理，从而实现指令的并行执行。流水线技术类似于工厂的装配线，可以显著提高指令吞吐量。
#### 流水线的基本概念
流水线将指令的执行过程划分为若干个阶段（通常为取指令、译码、执行、访存和写回等），每个阶段由专门的硬件单元负责处理。多个指令可以同时处于不同的阶段，从而实现并行处理。
一条指令的执行过程分为如下5个阶段：
1. **取指令 (IF)**：从内存中获取指令，并将其送入指令寄存器 (IR)。
2. **指令译码 (ID)**：解释指令的含义，确定需要执行的操作。
3. **执行 (EX)**：执行指令所要求的操作，如算术运算或逻辑运算。
4. **访存 (MEM)**：访问内存，读取或写入数据（对于需要访问内存的指令）。
5. **写回 (WB)**：将运算结果写回寄存器或内存。
![5段指令流水线](/picture/jizu-pipeline-5stage.png)

##### 流水线的基本实现
1.设计原则:指令流水段个数以最复杂指令的执行时间为准
2.每个流水段的工作时间应尽量相等，以避免某一段成为瓶颈。
3.流水段之间应有寄存器隔离，以存储各段的中间结果。

流水线时钟周期的计算：一段完整的指令所需时钟周期+（n-1）*最长流水段时间
n为流水段数。

前半段写后半段读，对于同一个时钟周期。

#### 流水线的冒险和处理
流水线在提高指令执行效率的同时，也会引入一些问题，主要包括数据冒险、控制冒险和结构冒险。
##### 1. 数据冒险
数据冒险是指由于指令之间的数据依赖关系，导致后续指令无法正确执行的情况。常见的数据冒险包括：
- **读后写 (RAW)**：后续指令需要读取前一指令写入的数据。
- **写后读 (WAR)**：前一指令需要写入的数据被后续指令读取。
- **写后写 (WAW)**：两条指令需要写入同一个寄存器或内存位置。
处理数据冒险的方法包括：
1 stall（暂停流水线）：通过插入气泡（NOP指令）来延迟后续指令的执行，直到数据依赖关系得到解决。
2 转发（数据旁路）：通过硬件实现数据的直接传递，避免等待数据写回寄存器。
3 load-use数据冒险的处理：在load指令后紧跟使用该数据的指令时，通常需要插入一个气泡，无法通过转发来实现。
例如：
```text
LW R1, 0(R2)  # Load word from memory to R1
ADD R3, R1, R4 # Use the loaded value in R1
```
在这种情况下，ADD 指令需要等待 LW 指令完成数据加载，因此需要插入一个气泡。无法通过转发解决。

##### 2. 控制冒险
控制冒险是指由于分支指令的存在，导致流水线无法确定下一条指令的执行路径，从而引发的冒险。处理控制冒险的方法包括：
1. 分支预测：通过预测分支的结果，提前加载可能的下一条指令。
2. 延迟分支：将分支指令后的若干条指令作为延迟槽，无论分支是否发生，这些指令都会被执行。
3. 流水线冲刷：当分支预测错误时，清除错误的指令，并重新加载正确的指令。
做题技巧：出现分支指令，阻塞流水线，一般会有两个气泡。
例如：
```text
BEQ R1, R2, LABEL  # Branch if equal
NOP                  # Delay slot 1 
NOP                  # Delay slot 2
```
##### 3. 结构冒险
结构冒险是指由于硬件资源的限制，导致流水线无法同时处理多条指令的情况。例如，如果只有一个内存端口，而同时有多条指令需要访问内存，就会发生结构冒险。处理结构冒险的方法包括：
1. 增加硬件资源：如增加内存端口或寄存器堆。
2. 资源调度：通过调度指令的执行顺序，避免同时访问同一资源。

#### 流水线的性能指标
流水线的性能通常通过以下几个指标来衡量：
1. **吞吐率 (Throughput)**：单位时间内完成的指令数量。吞吐量越高，表示流水线的效率越高。计算公式：吞吐率 = 任务数 / 这些任务的总时间

3. **加速比 (Speedup)**：流水线执行与非流水线执行的速度比。计算公式：加速比 = 非流水线执行时间 / 流水线执行时间
一条k段流水线完成n个任务所需的时间为：T = (k + n - 1) * Tc
Tc为流水线时钟周期。顺序执行时间为：Tseq = n * k * Tc
则加速比为：S = Tseq / T = n*k*Tc / ((k + n - 1)*Tc) = n*k / (k + n - 1)最大加速比趋近于k。

### 高级流水线技术
#### 超标量技术
超标量技术是一种通过在单个时钟周期内发射多条指令来提高 CPU 性能的技术。超标量处理器具有多个执行单元，可以同时处理多条指令，从而实现更高的指令级并行性。
两种技术：
1.多发射技术：在一个时钟周期内发射多条指令。使得流水线能同时处理多条指令。此时CPI<1，成本更高，控制更复杂。
2.超流水线技术：通过增加流水线的阶段数，使得每个阶段的工作时间更短，从而提高时钟频率。CPI=1,但时钟周期更短。主频更高。

### 多处理器
似乎没怎么讲，暂时跳过。


常见问题：
1.流水线越多，并行度越高，是否流水线越多指令执行效率越高？
答：不一定。流水线段数增加会带来更高的时钟频率，但也会增加流水线冒险的概率和复杂性，可能导致更多的气泡和停顿，从而降低整体效率。因此，流水线段数的增加需要权衡利弊。
除此之外，流水线缓冲区的增加也会带来额外的开销，如功耗和芯片面积的增加。因此，设计流水线时需要综合考虑各种因素，以实现最佳性能。

2.为什么load-use数据冒险无法通过转发解决？
答：load-use数据冒险无法通过转发解决的原因在于，load指令从内存中加载数据需要一定的时间，而在这段时间内，后续指令已经进入流水线并试图使用该数据。由于数据尚未从内存加载到寄存器，转发机制无法提供所需的数据，因此必须通过插入气泡来延迟后续指令的执行，直到数据加载完成。

3.为什么分支指令会引起两个气泡？
答：分支指令会引起两个气泡的原因是，在分支指令执行时，CPU无法立即确定下一条指令的地址，因为这取决于分支条件是否成立。在流水线中，分支指令通常需要两个周期来完成：一个周期用于评估分支条件，另一个周期用于获取正确的下一条指令。因此，在这两个周期内，流水线无法继续执行后续指令，从而产生两个气泡。

4.为什么处理控制冒险要冲刷流水线？
答：处理控制冒险时需要冲刷水线的原因是，当分支预测错误时，已经加载到流水线中的指令可能不再是正确的执行路径。为了确保程序的正确性，必须清除这些错误的指令，并重新加载正确的指令。这一过程称为冲刷水线，通过清除错误指令，可以避免错误执行对程序状态造成的不良影响。

5.读后写和写后写相关概念
读后写（Read After Write, RAW）：也称为真实依赖，指的是后一条指令需要读取前一条指令写入的数据。如果前一条指令尚未完成写操作，后一条指令就无法获取正确的数据，导致数据冒险。
写后写（Write After Write, WAW）：也称为输出依赖，指的是两条指令都试图写入同一个寄存器或内存位置。如果后一条指令在前一条指令完成写操作之前执行，就会导致数据冲突，影响程序的正确性。
例子：
```text
MOV R1, #5      ; 指令1：将5写入R1
ADD R1, R1, #10  ; 指令2：将R1的值加10后写回R1
```
在这个例子中，指令2依赖于指令1的结果，因此存在读后写（RAW）依赖关系。如果指令2在指令1完成之前执行，就会导致数据冒险。

写后写（WAW）依赖关系的例子：
```text
MOV R1, #5      ; 指令1：将5写入R1
MOV R1, #10     ; 指令2：将10写入R1
```
在这个例子中，指令1和指令2都试图写入R1寄存器。如果指令2在指令1完成之前执行，就会导致写后写（WAW）依赖关系，可能导致R1的最终值不正确。


## 【六】总线系统

### 总线

### 总线基本概念
总线定义：
总线是计算机系统中各个部件之间传输数据、地址和控制信息的公共通路。它由多条并行的导线组成，允许多个设备共享同一组信号线进行通信。

分时和共享式总线的两个特点：
- **分时**：同一时刻只允许有一个部件向总线发送信息。若系统中有多个部件，则它们只能分时地向总线发送信息。
- **共享**：总线上可以挂接多个部件，这些部件可以同时从总线上接受相同的信息。

总线设备：
- **总线主设备**：能够主动地向总线发送信息的设备，如CPU、DMA控制器等。
- **总线从设备**：只能被动地从总线接受信息的设备，如内存、输入/输出设备等。

总线宽度：总线中数据线的位数，通常为8位、16位、32位或64位等。
总线周期：完成一次总线操作所需的时间，包括地址传输、数据传输和控制信号等阶段。

### 总线的分类
1. **按功能层次分类**：
   - **片内总线**：位于芯片内部，用于连接芯片内的各个功能模块，如CPU内部的ALU与寄存器之间的连接。
   - **系统总线**：连接CPU、内存和高速I/O设备的主干总线，包括数据总线、地址总线和控制总线。
   - **IO总线**：连接低速I/O设备和外设的总线，如PCI、USB等，用于扩展系统功能。
   - **通信总线**：用于计算机之间或计算机与网络之间的通信，如Ethernet、Wi-Fi等。

2. **按时序控制方式分类**：
   - **同步总线**：所有操作都由统一的时钟信号控制，传输速度快，但对时钟同步要求高。适用于高速传输场景。
   - **异步总线**：使用握手信号进行控制，不依赖统一时钟，灵活性强，但速度较慢。适用于不同速度设备的连接。

3. **按数据传输方式分类**：
   - **串行总线**：数据一位一位地顺序传输，线缆简单，适用于长距离传输，如USB、SATA。
   - **并行总线**：数据多位同时传输，速度快，但线缆复杂，易受干扰，如ISA、PCI总线。

### 总线上传输的内容
系统总线通常由三类信号线组成：数据总线、地址总线和控制总线。以下是各部分的详细说明：

- **数据总线 (Data Bus)**：
  - **功能**：负责传输数据信息，包括指令、操作数和结果。位数反映一次能传输的数据的位数。
  - **方向**：双向传输，既可从主设备发送到从设备，也可反向传输。
  - **特点**：宽度通常为8位、16位、32位或64位，宽度越大，每次传输的数据量越大，效率越高。
  - **示例**：在32位数据总线上，一次可传输4字节数据。

- **地址总线 (Address Bus)**：
  - **功能**：传输地址信息，用于指定数据传输的目标位置，如内存地址或I/O端口地址。
  - **方向**：单向传输，从主设备（如CPU）发送到从设备。
  - **特点**：位数决定系统的寻址空间大小，例如，32位地址总线可寻址2^32 = 4GB的地址空间。
  - **示例**：CPU通过地址总线发送内存单元的地址，从设备据此读取或写入数据。

- **控制总线 (Control Bus)**：
  - **功能**：传输控制信号，确保数据传输的正确性和时序，包括读/写操作、时钟同步、中断请求等。
  - **方向**：多为单向，但某些信号可能双向。
  - **特点**：信号种类多样，包括时钟信号（CLK）、读信号（RD）、写信号（WR）、中断请求（IRQ）等。
  - **示例**：读信号激活时，从设备将数据放到数据总线上；写信号激活时，主设备将数据发送到从设备。

### 常见的总线标准
总线标准是国际上公布的互连各个模块的标准，是吧不同的模块组成计算机系统时必须遵守的规范。常见的总线标准有：
- **ISA (Industry Standard Architecture)**：早期的16位总线标准，主要用于连接低速I/O设备。
- **PCI (Peripheral Component Interconnect)**：32位或64位并行总线，支持即插即用，广泛用于连接显卡、网卡等高速设备。
- **PCIe (PCI Express)**：高速串行总线，取代了传统的PCI标准，提供更高的数据传输速率和更好的扩展性。
- **USB (Universal Serial Bus)**：通用串行总线，广泛用于连接各种外设，如键盘、鼠标、存储设备等，支持热插拔。
- **SATA (Serial ATA)**：串行总线标准，主要用于连接存储设备，如硬盘和固态硬盘，提供高速数据传输。
它们的主要区别是总线宽度，带宽，时钟频率，寻址方式，是否支持突发传送等等。

下面为一些总线：
1. **ISA (Industry Standard Architecture)**：早期的16位并行总线标准，主要用于连接低速I/O设备，如键盘、鼠标等。数据宽度16位，频率8MHz。
2. **EISA (Extended ISA)**：ISA的32位扩展版本，兼容ISA设备，支持更高的数据传输速率，用于服务器和高端PC。
   - **区分设备总线和局部总线**：设备总线（如ISA、EISA）主要连接低速外设，局部总线（如VESA、PCI）连接高速设备，提供更高的带宽和性能。
3. **VESA (Video Electronics Standards Association)**：本地总线标准，专为显卡设计，提供更高的带宽以支持图形处理。
4. **PCI (Peripheral Component Interconnect)**：32位或64位并行总线，支持即插即用，广泛用于连接显卡、网卡等高速设备。时钟频率33MHz。
5. **AGP (Accelerated Graphics Port)**：专用于显卡的32位总线，提供直接内存访问，提高图形性能。
   - **PCI-E总线的特点**：PCI-E是高速串行总线，支持点对点连接（不同于PCI的共享总线），提供更高的数据传输速率（如PCIe 3.0可达8GT/s），支持热插拔和扩展性强。版本包括1.0、2.0、3.0、4.0、5.0等。
6. **PCI-E (PCI Express)**：高速串行总线，取代PCI，支持点对点连接，提供更高的数据传输速率和扩展性。
7. **RS-232C**：串行通信标准，用于计算机与外设（如调制解调器）的连接，支持异步传输。
   - **USB总线的特点**：USB支持热插拔、即插即用，传输速率高（USB 2.0为480Mbps，USB 3.0为5Gbps），支持多种设备类型，供电能力强，可为设备供电。版本演进包括1.1、2.0、3.0、3.1、4.0等。
8. **USB (Universal Serial Bus)**：通用串行总线，支持热插拔，广泛用于连接键盘、鼠标、存储设备等。版本包括USB 2.0、3.0等。
9. **PCMCIA (Personal Computer Memory Card International Association)**：PC卡标准，用于笔记本电脑的扩展槽，支持内存卡和I/O设备。
10. **IDE (Integrated Drive Electronics)**：并行ATA总线，用于连接硬盘驱动器，支持ATA标准的数据传输。
11. **SCSI (Small Computer System Interface)**：高速并行总线，用于连接存储设备和外设，支持多设备连接和高速传输。
12. **SATA (Serial ATA)**：串行ATA总线，取代IDE，提供更高的数据传输速率和更好的热插拔支持。

### 总线的性能指标
总线的性能通过以下指标衡量，这些指标影响数据传输的速度和效率：

1. **总线时钟周期**：时钟信号的周期长度，表示总线时钟的一个完整周期所需的时间，通常以纳秒（ns）为单位。周期越短，传输速度越快。
2. **总线时钟频率**：时钟信号的频率，表示每秒钟时钟周期的次数，单位为MHz或GHz。频率越高，总线工作越快。
3. **总线传输周期**：完成一次完整数据传输（包括地址、数据和控制信号）所需的时间。它是总线操作的基本时间单位。
4. **总线工作频率**：总线实际运行的频率，可能与时钟频率相同或不同，取决于总线协议和设计。
5. **总线宽度**：数据总线的位数，表示一次传输的数据量，如16位、32位或64位。宽度越大，单次传输的数据越多。
6. **总线带宽**：单位时间内传输的数据量，计算公式为：带宽 = 数据宽度 × 时钟频率 × 传输效率。单位通常为MB/s或GB/s。
7. **总线复用**：指信号线是否被复用，如地址线和数据线共享同一组信号线，以减少线缆数量，但可能影响速度。
8. **信号线数**：总线中所有信号线的总数，包括数据线、地址线和控制线。线数越多，功能越复杂，但成本和复杂性也增加。

相关计算知识与技巧：
1. **带宽计算**：带宽 = 数据宽度（位） × 时钟频率（Hz） / 8（转换为字节）。例如，32位数据总线，时钟频率为100MHz，则带宽 = 32 × 100,000,000 / 8 = 400MB/s。
2. **寻址空间计算**：寻址空间 = 2^(地址总线位数)。例如，32位地址总线可寻址2^32 = 4GB的内存空间。
3. **传输时间计算**：传输时间 = 数据量（字节） / 带宽（字节/秒）。例如，传输1MB数据，带宽为400MB/s，则传输时间 = 1,000,000 / 400,000,000 = 0.0025秒。
4. **总线周期与频率关系**：总线周期（秒） = 1 / 总线频率（Hz）。例如，100MHz总线频率对应的周期为1 / 100,000,000 = 10纳秒。
5. **复用影响**：复用信号线可能导致传输延迟增加，因为同一组线需要在不同时间段传输不同类型的信息，需考虑切换时间。

### 总线的事务和定时
#### 总线事务
**定义**：从请求总线到完成总线使用的操作序列称为总线事务，它是在一个总线周期中发生的一系列的活动。

总线事务通常分为以下五个阶段：

1. **请求阶段**：主设备（如CPU或DMA控制器）向总线仲裁器发出总线使用请求，表示需要访问总线进行数据传输。
2. **仲裁阶段**：总线仲裁器根据仲裁算法（如优先级或轮询）决定哪个主设备获得总线控制权，其他设备等待。
3. **寻址阶段**：获得控制权的主设备通过地址总线发送目标地址信息，指定数据传输的目的地（如内存地址或I/O端口）。
4. **传输阶段**：主设备和从设备之间进行实际的数据传输，包括读或写操作，通过数据总线交换信息。
5. **释放阶段**：数据传输完成后，主设备释放总线控制权，总线回到空闲状态，准备响应下一个请求。

#### 总线定时
总线定时方式决定了总线操作的时序控制，主要有以下几种：

1. **同步定时方式**：所有总线操作都由统一的时钟信号控制，设备必须在时钟边沿同步进行操作。优点是速度快、简单；缺点是对时钟同步要求高，适用于高速设备。
2. **异步定时方式**：不依赖统一时钟，使用握手信号（如请求和应答）控制传输。优点是灵活性强，适用于不同速度设备；缺点是速度较慢，协议复杂。
   - 根据请求和应答信号的撤销是否互锁，还可以细分为：
    -  **不互锁握手**：主设备撤销请求信号后，从设备可以立即撤销应答信号，无需等待确认。优点是速度快；缺点是可能导致数据丢失或冲突。
     - **半互锁握手**：主设备撤销请求信号后，从设备可以立即撤销应答信号，无需等待进一步确认。优点是响应快；缺点可能导致信号冲突。
     - **全互锁握手**：主设备撤销请求信号后，从设备保持应答信号有效，直到主设备确认接收后再撤销。优点是可靠性高，避免误操作；缺点是效率稍低。

3. **半同步定时方式**：结合同步和异步，使用时钟信号但允许一定延迟，通过握手信号调整。优点是兼顾速度和灵活性，适用于混合环境。
4. **分离式定时方式**：地址传输和数据传输分离，先传输地址，再传输数据，提高总线利用率。优点是效率高，减少等待时间；适用于需要高吞吐量的场景。
## 【七】输入输出系统（I/O）

> **概述**：本笔记涵盖 I/O 系统的基本概念、接口、端口编址以及各种 I/O 控制方式。重点理解程序查询、中断、DMA 和通道方式的区别与应用。

### I/O 系统基本概念

#### 输入输出系统

基本概念如下：
- **外部设备**：计算机系统外部的设备，如硬盘、显示器、键盘等。
- **接口**：连接外部设备和计算机系统的桥梁，负责数据传输和控制信号的传递。
- **输入设备**：将外部信息转换为计算机可处理的形式的设备，如键盘、鼠标、扫描仪等。
- **输出设备**：将计算机处理结果转换为人类可理解形式的设备，如显示器、打印机等。
- **外存设备**：用于长期存储数据的设备，如硬盘、光盘、U盘等。

一般来说，IO系统由两部分构成：
1. **IO软件**：
   - 包括驱动程序，用户程序，管理程序，升级补丁等。
   - 通常采用IO指令和通道指令实现CPU与IO设备之间的数据传输。
2. **IO硬件**：
   - 包括外部设备，设备控制器和接口，IO总线等。
   - 通过设备控制器来控制IO设备的具体操作；通过IO接口与主机（总线）相连。

### 外部设备

#### 1. 输入设备
- **键盘**：用于输入字符和命令，是计算机最基本的输入设备。
- **鼠标**：用于控制光标位置和选择操作对象。

#### 2. 输出设备
- **显示器**：用于显示计算机处理结果的设备。
  - 主要参数：
    - **分辨率**：显示器能够显示的像素数量，通常以宽度×高度表示（如1920×1080）。
    - **刷新率**：显示器每秒钟更新图像的次数，通常以Hz表示。
    - **灰度级别**：显示器能够显示的灰度级别数量，通常以位数表示。
    - **持久性**：荧光只能保持极短的时间（针对CRT显示器）。
- **打印机**：用于将计算机处理结果打印到纸张上的设备。
  - 分类：
    - 按照打印技术分类：点阵式打印机、喷墨打印机、激光打印机等。
    - 按照打印速度分类：高速打印机、普通打印机等。

#### 3. 外部存储器
- **SSD**：固态硬盘，采用闪存技术存储数据，具有高速读写和抗震性能。
- **HDD**：机械硬盘，采用磁盘技术存储数据，具有大容量和低成本优势。
- **光盘**：采用激光技术存储数据，具有便携性和易于共享的特点。
- **U盘**：采用闪存技术存储数据，具有便携性和易于使用的特点。

### IO控制方式
基本控制方式主要由以下四种：
1. **程序查询方式**：由CPU通过轮询方式查询IO设备状态，等待设备准备好后进行数据传输。
2. **中断方式**：由IO设备在准备好后向CPU发送中断信号，CPU响应中断请求后进行数据传输。
3. **DMA方式**：由DMA控制器直接控制IO设备和内存之间的数据传输，减轻CPU负担。
4. **通道方式**：由专门的通道处理器控制IO设备和内存之间的数据传输，提高数据传输效率。

**记忆窍门**：
- 程序查询方式：CPU忙着查询（程序员自己查）
- 中断方式：IO设备打电话给CPU（IO设备中断CPU）
- DMA方式：DMA控制器帮忙传数据（DMA代劳）
- 通道方式：通道处理器专门传数据（通道专职）

## IO接口

### 接口的功能
主要功能如下：
1. **进行地址译码和设备选择**
   - 接口负责把来自主机的地址信号译码成特定外设的片选(chip-select)或端口选通信号。通过固定基址、地址映射或门控译码逻辑，将主机地址空间中的某一段映射到对应的设备寄存器或数据端口，从而实现对设备的定向访问。

2. **实现主机和外设的通信联络控制**
   - 接口管理数据传输的时序与控制信号（如读/写(strobe)、请求/确认、就绪(READY)、中断请求等），并根据握手机制(handshaking)协调主机与外设的数据交换，保证在速率或时序不匹配时仍能可靠通信。

3. **实现数据缓冲**
   - 接口通常包含缓冲区或FIFO，用于暂存数据以适应主机与外设之间的速率差异；缓冲还支持双缓冲或环形缓冲以减少丢失并提高吞吐量，必要时还负责字宽对齐和打包/拆包操作。

4. **信号格式的转换**
   - 接口负责信号电平和格式的转换，例如电压/电平移位、串/并转换、编码/解码（如NRZ、Manchester）、校验与帧格式处理、字节序(endian)转换等，以便外设与主机能在物理和逻辑层面相互理解数据。

5. **传送控制命令和状态信息**
   - 接口提供控制寄存器和状态寄存器，用于主机向外设发出命令（如启动、停止、配置参数）以及外设向主机报告状态、完成标志或错误信息。接口还负责中断产生、错误标志置位和状态轮询等机制，便于操作系统或驱动程序管理设备。

### 接口的基本结构
接口的基本结构包括以下几个部分：
1. **数据缓冲区（Buffer / FIFO）**：用于暂存数据，协调主机与外设之间的速率差异；常见功能包括双缓冲、环形缓冲、字宽对齐和流控。
2. **状态/控制寄存器**：提供配置位、控制命令位、就绪/完成/错误状态位等，主机通过读/写这些寄存器管理设备。
3. **地址译码与片选逻辑**：把主机地址映射到具体设备或设备内寄存器，生成片选信号（CS）或端口选通信号。
4. **握手与中断逻辑**：实现读/写握手（如REQ/ACK、RD/WR、STB/ACK）、就绪检测、以及中断请求（IRQ）产生与清除。
5. **物理/电平与格式转换模块**：包含电平移位、时钟域跨越同步、串/并转换、编码/解码和校验等，用于物理层兼容与可靠传输。

**IO接口的数据线上传输的内容（典型说明）**：
- **数据线**：
  - 传输内容：设备与主机之间实际的数据字（如读出的数据或写入的数据）。
  - 要点：数据总线可能为双向；需注意字节序、对齐、字宽扩展/收缩；可带奇偶校验或CRC以检测错误。
  - 示例信号：`DATA[7:0]`、`DATA[15:0]`、`DATA_IN`/`DATA_OUT`、`FIFO_DATA`。

- **地址线**：
  - 传输内容：用于选择目标设备或设备内寄存器的地址/端口号。
  - 要点：地址的高位通常用于设备选择，低位用于寄存器偏移；地址映射可为内存映射I/O或端口映射I/O。
  - 示例信号：`ADDR[15:0]`、`A0..An`，译码后产生 `CS`（片选）。

- **控制线**：
  - 传输内容：控制与时序信号，指示操作类型与数据何时有效。
  - 常见信号：`RD`（读）、`WR`（写）、`STB`/`STRB`（选通信号/字节选通）、`ACK`/`READY`（确认/就绪）、`IRQ`（中断请求）、`RESET`、`CLK`（时钟）。
  - 要点：控制线实现握手与同步，决定读/写操作的开始/结束并触发中断或错误处理。

这些模块与信号协同工作，形成既能处理物理层差异又能向操作系统或驱动暴露清晰控制/状态接口的IO接口。

## IO接口的类型
IO接口的类型主要有以下几种：

### 1. 按数据传送方式
- **并行接口**：一字节或一个字的所有位同时传送，传输速率高、延迟低，但需要多条数据线，适合短距离高速连接（例如本地总线）。
- **串行接口**：数据按位序列传输，线数少、适合长距离和高频率链路（如USB、SPI、UART），通常通过收发器或串并转换实现性能/复杂度折中。

### 2. 按主机访问IO设备的控制方式
- **程序查询（轮询）**：CPU不断检查设备状态并发起传输，简单但CPU占用高。
- **中断方式**：设备就绪时产生中断，CPU中断处理程序处理I/O，响应性好，CPU利用率提高。
- **DMA方式**：DMA控制器在主存与设备间直接传输数据，CPU仅做控制，适用于大块数据传输以降低CPU负载。

### 3. 按功能选择的灵活性
- **可编程接口**：接口含可配置寄存器或固件，功能可通过软件改变，适合通用设备或需要多种工作模式的外设。
- **专用接口**：功能固定、实现简单且高效，适用于专用外设或对性能/成本敏感的场景。

## IO端口及其编址
IO端口是计算机系统中用于与外设通信的逻辑地址空间。每个IO设备通常分配一个或多个端口号，主机通过这些端口号与设备进行数据交换和控制操作。主要有：数据端口，状态端口和控制端口。

IO端口想要被CPU访问，就必须对各个接口的端口进行编址。每个端口对应一个端口地址。

IO端口的编址方式：

### 1. 独立编址（端口映射 I/O / Port-mapped I/O）
- **概念**：为 I/O 设备保留一段与主存分离的 I/O 地址空间，CPU 使用专门的 I/O 指令（如 x86 的 `IN`/`OUT`）访问这些端口，地址称为端口号。
- **优点**：与内存地址空间隔离，避免与主存地址冲突；译码逻辑通常较简单；硬件上可独立管理访问权限。
- **缺点**：需要专用指令或特殊访问方式，编程不如内存映射灵活；I/O 地址空间通常较小，扩展受限；对现代编译器/体系支持较弱。

### 2. 统一编址（内存映射 I/O / Memory-mapped I/O）
- **概念**：将设备寄存器映射到主存的地址空间，CPU 使用普通内存读写指令访问设备，设备寄存器表现为特定的内存地址范围。
- **优点**：编程简单（可用普通 load/store 指令）、易于与高级语言/编译器集成；可利用指令集、缓存机制（需处理一致性）和DMA进行高效访问；地址空间灵活。
- **缺点**：占用内存地址空间（对地址受限的平台可能是问题）；需要处理缓存一致性和内存屏障以保证设备寄存器访问的可见性；硬件设计和保护机制更复杂。

**小结/选型要点**：
- 嵌入式或资源受限系统常用内存映射以简化编程；某些架构保留端口映射以节省内存地址或出于历史兼容。
- 设计接口时需考虑地址空间、访问指令集支持、缓存一致性、性能与编程便利性等因素。

## I/O方式

---

## 一、程序查询方式（Polling）

程序查询方式（也称为轮询方式）是一种最基本的 I/O 控制方式，由 CPU 主动查询外设状态来完成数据传输。

### 工作流程
1. CPU 执行初始化程序，设置 I/O 设备的控制寄存器，准备数据传输。
2. 向 I/O 接口发出命令字，启动 I/O 设备工作。
3. CPU 从外设接口读取状态寄存器，判断设备是否就绪。
4. 若设备未就绪，CPU 继续查询设备状态（轮询）。
5. 设备就绪后，CPU 与设备进行一次数据传输。
6. 修改设备状态、内存地址寄存器和计数器，为下一次传输做准备。
7. 重复步骤 3～6，直到计数器为 0，数据传输完成。

### 查询方式分类

#### 1. 固定时间间隔查询
- **特点**：CPU 按固定时间间隔查询设备状态。
- **适用场景**：设备响应时间稳定。
- **优点**：
  - 实现简单
  - 易于编程和调试
- **缺点**：
  - 响应时间变化大时效率低
  - 可能浪费 CPU 时间

#### 2. 连续查询
- **特点**：CPU 不间断地查询设备状态。
- **适用场景**：设备响应时间不确定、低速或简单外设。
- **优点**：
  - 实现最简单
  - 响应及时
- **缺点**：
  - CPU 占用率极高
  - 无法并行执行其他任务
  - 不适用于高速设备

---

## 二、中断方式（Interrupt）

中断方式是一种高效的 I/O 控制方式，由外设在需要服务时主动向 CPU 发出中断请求，实现 CPU 与 I/O 的并行工作。

### 中断方式的主要作用
1. **实现并行工作**：CPU 不必等待 I/O，可先执行其他程序。
2. **异常与错误处理**：硬件故障或软件异常通过中断上报。
3. **人机交互**：键盘、鼠标等输入设备通过中断触发响应。
4. **支持多道程序与分时系统**：用于时间片到期与进程切换。
5. **满足实时性要求**：对紧急事件可快速响应。
6. **特权与模式切换**：系统调用通过中断从用户态进入内核态。
7. **多处理器协同**：通过处理器间中断（IPI）实现 CPU 间通信。

### 中断流程

1. **中断请求（IRQ）**  
   外设通过中断控制器向 CPU 发出中断请求信号。
2. **中断响应**  
   CPU 在完成当前指令后检查中断请求，若满足条件则响应。
3. **中断响应条件**
   - 中断允许（未被屏蔽）
   - 中断优先级高于当前执行级别
4. **中断响应过程**
   - 关中断
   - 保存断点（PC、PSW 等）
   - 根据中断向量转入中断服务程序

### 中断向量与中断识别
- **向量中断**  
  每个中断源对应一个唯一的中断向量，CPU 可直接定位 ISR。
- **非向量中断**  
  CPU 需查询中断控制器或设备状态来确定中断源。

### 中断处理的完整过程
1. 关中断  
2. 保存断点  
3. 中断服务程序寻址  
4. 保存现场与屏蔽字  
5. 开中断  
6. 执行中断服务程序（ISR）  
7. 关中断  
8. 恢复现场与屏蔽字  
9. 开中断并返回原程序  

### 多重中断与中断屏蔽
- **多重中断**：允许中断嵌套，高优先级中断可打断低优先级中断。
- **中断屏蔽**：通过屏蔽寄存器禁止或允许特定中断源，保证系统稳定性。

---

## 三、DMA方式（Direct Memory Access）

DMA 是一种高速 I/O 数据传输方式，允许外设在 DMA 控制器的控制下直接与内存交换数据，CPU 仅进行初始化和结束处理。

### DMA 的特点
- 数据传输不经过 CPU
- CPU 只在开始和结束时参与
- 传输速度快
- 显著降低 CPU 负担
- 适用于高速、大批量数据传输（如磁盘、网卡）

### DMA 控制器的组成
- **地址寄存器**：存放内存起始地址
- **计数器**：记录传输数据的字节数/字数
- **控制寄存器**：指定传输方向和模式
- **状态寄存器**：反映 DMA 工作状态

### DMA 的传送方式
1. **停止 CPU 方式（独占方式）**
   - DMA 传输期间 CPU 暂停
   - 实现简单，但影响 CPU 性能
2. **周期挪用方式**
   - DMA 每次只占用一个总线周期
   - CPU 与 DMA 交替访问内存
3. **透明 DMA 方式**
   - CPU 空闲时才进行 DMA 传输
   - 对 CPU 影响最小，但速度较慢

### DMA 的传送过程（更详细版）

> 目标：让外设在 **DMA 控制器** 的管理下，直接把数据写入/读出 **主存**，CPU 只负责“安排 + 收尾”。

#### 0）前提：相关硬件/信号
- **DMA 控制器寄存器**：内存地址寄存器（MAR）、传输计数器（COUNT）、控制/模式寄存器（方向、传输单位、是否自增、是否中断等）、状态寄存器。
- **总线仲裁信号**（不同体系命名不同）：DMA 请求总线（BR/HRQ）、CPU 授权总线（BG/HLDA）。
- **外设握手信号**：设备就绪/请求（DREQ）、DMA 应答（DACK）等。
- **中断线**：DMA 结束或异常后向 CPU 产生中断请求。

---

#### 1）CPU 初始化 DMA（“下单”阶段）
1. **确定传输参数**（由驱动/OS 完成）：
   - 传输方向：外设→内存（输入）或 内存→外设（输出）
   - 传输长度：N 个字节/字/块
   - 内存起始地址（缓冲区首地址）
   - 传输单位与模式：字节/字；单次/块传输；是否地址自增；是否需要完成中断等
2. **写 DMA 寄存器**：
   - 将起始地址写入 **地址寄存器 MAR**
   - 将传输数量写入 **计数器 COUNT**
   - 将方向/模式写入 **控制寄存器 CTRL**
3. **清状态 + 使能通道**：
   - 清除 DMA 完成标志/错误标志
   - 使能对应 DMA 通道（Enable Channel）

---

#### 2）启动 DMA 与外设（“开工”阶段）
1. CPU 向外设写入命令字，让外设进入 DMA 工作模式（比如：启动磁盘读扇区、网卡接收等）。
2. CPU **继续执行其他程序**（不再轮询每个数据，不参与搬运）。

---

#### 3）DMA 请求并获得总线控制权（“抢总线”阶段）
1. 外设准备好要传的数据时，向 DMA 发出 **DREQ（设备请求）**。
2. DMA 控制器向 CPU/总线仲裁器发出 **总线请求**（BR/HRQ）。
3. CPU 在 **当前指令结束** 或到达可让出总线的时刻：
   - 进入让总线状态（视实现：可能暂停访存周期）
   - 回送 **总线授权**（BG/HLDA）
4. DMA 获得总线主控权：此时 DMA 成为“临时总线主设备”，可以发起内存读/写周期。

> 注意：不同 DMA 方式会影响 CPU 被“打断”的程度  
> - **停止 CPU（Burst/Block）**：DMA 连续占总线直到传完  
> - **周期挪用（Cycle Stealing）**：DMA 每次只偷一个/几个总线周期  
> - **透明 DMA**：只在 CPU 不用总线时传（对 CPU 影响最小）

---

#### 4）执行一次 DMA 传输基本循环（“搬运”阶段）
以 **外设 → 内存** 为例（输入）：

1. **DMA 对外设发出 DACK**（应答），告诉外设“我来取数据”。
2. **DMA 发起 I/O 读 + 内存写**（具体实现可能分成两个总线周期）：
   - 从外设数据寄存器读出一个传输单位（字节/字）
   - 写入内存地址寄存器指向的内存单元
3. **更新寄存器**：
   - MAR（内存地址）按传输单位 **自增**（或固定不变，取决于模式）
   - COUNT（计数器）**减 1**
4. **检查是否完成**：
   - 若 COUNT ≠ 0：继续下一次搬运循环
   - 若 COUNT = 0：进入结束阶段

> 若是 **内存 → 外设**（输出），则过程对称：DMA 先读内存，再写外设。

---

#### 5）DMA 结束处理（“收尾”阶段）
1. DMA 完成最后一次传输后：
   - 置位 **完成标志（TC：Terminal Count）** 或 Done 状态
   - 可选：更新状态寄存器记录完成/错误原因
2. DMA **释放总线**：
   - 撤销 BR/HRQ，总线控制权归还 CPU
   - CPU 继续正常访存与执行流

---

#### 6）DMA 通知 CPU（“交付结果”阶段）
1. 若配置为“完成中断”，DMA 向 CPU 发出 **中断请求**：
   - CPU 响应中断，进入 DMA 中断服务程序（ISR）
2. ISR 常见工作：
   - 检查 DMA 状态寄存器（确认完成还是异常：溢出/总线错误等）
   - 唤醒等待该 I/O 的进程/线程（解除阻塞）
   - 将缓冲区交给上层（文件系统、网络协议栈等）
   - 可能启动下一次 DMA（链式/双缓冲）

---

#### 7）常见优化：双缓冲/环形缓冲（理解用）
- 为避免 CPU 处理数据时 DMA 停摆，常用：
  - **双缓冲**：DMA 写 A 缓冲时 CPU 处理 B 缓冲
  - **环形缓冲**：持续流式输入（网卡/声卡）更常见

---

---

## 四、DMA方式与中断方式的比较

| 对比项       | 中断方式                  | DMA方式                  |
|--------------|---------------------------|--------------------------|
| CPU 参与度   | 每次数据传输都需 CPU 处理 | 仅开始和结束时参与      |
| 数据传输路径 | 外设 → CPU → 内存        | 外设 → 内存             |
| 传输效率     | 中等                      | 高                       |
| 适用场景     | 中低速设备、少量数据      | 高速设备、大量数据       |
| 硬件复杂度   | 较低                      | 较高                     |
| 系统开销     | 中断频繁时开销大          | 系统开销小               |

---

## 总结
- **程序查询方式**：简单但效率最低，适用于低速、小量数据传输。
- **中断方式**：兼顾效率与灵活性，支持并行工作，适用于中低速设备。
- **DMA方式**：效率最高，适合高速、大批量数据传输，显著减轻CPU负担。
- **通道方式**：进一步提高效率，由专用处理器控制，适用于复杂I/O系统。

现代操作系统通常 **结合使用中断和 DMA** 来实现高性能 I/O，例如在磁盘I/O中，DMA传输数据，中断通知完成。

**复习提示**：
- 重点掌握四种方式的工作流程和优缺点。
- 理解接口的功能和结构。
- 注意端口编址的两种方式及其区别。
- 练习比较不同I/O方式的适用场景。



